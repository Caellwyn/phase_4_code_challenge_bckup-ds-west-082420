{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "index (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcbEUF0joMQ4"
      },
      "source": [
        "# Mod 4 Code Challenge: Product Reviews\n",
        "\n",
        "This assessment is designed to test your understanding of these areas:\n",
        "\n",
        "1. Data Engineering\n",
        "    - Understanding an existing ETL pipeline\n",
        "    - Feature scaling\n",
        "2. Deep Learning with Neural Networks\n",
        "    - Creating a TensorFlow neural network model\n",
        "    - Fitting the model on training data\n",
        "    - Hyperparameter tuning\n",
        "    - Model evaluation on test data\n",
        "3. Business Understanding and Technical Communication\n",
        "    - Advising a business on what kind of model architecture to use\n",
        "\n",
        "**Unlike previous challenges, we have provided you some pre-existing code.**  Your work, markdown and code, should build off of the pre-existing material. \n",
        "\n",
        "Make sure that your code is clean and readable, and that each step of your process is documented. For this challenge each step builds upon the step before it. If you are having issues finishing one of the steps completely, move on to the next step to attempt every section.  There will be occasional hints to help you move on to the next step if you get stuck, but attempt to follow the requirements whenever possible. \n",
        "\n",
        "### Business Understanding\n",
        "\n",
        "Northwind Trading Company allows customers to leave reviews, but those reviews do not have customer-facing \"star ratings\".  Instead, customers are free to write text, and other customers can vote on whether the review was helpful.  They find that this is a good trade-off between helping customers make informed decisions about products, and avoiding having any products go unsold because of poor ratings.\n",
        "\n",
        "Internally, Northwind is interested to know which of these reviews are positive, and which are negative.  **A previous employee of the company has already built a Random Forest Classifier model to perform this classification task.**\n",
        "\n",
        "Northwind management has heard great things about using Artificial Intelligence for this kind of task, especially Neural Networks like TensorFlow.  **You have been instructed to build a TensorFlow model and advise the company on whether they should switch from the Random Forest Classifier to the TensorFlow model.**\n",
        "\n",
        "In either case, you want a **classification model** that optimizes for **accuracy**.\n",
        "\n",
        "### Data Understanding\n",
        "\n",
        "The data has already been described, imported, and preprocessed in this notebook.\n",
        "\n",
        "****Below is the work of a previous employee. Take a brief moment to review their work and then complete the tasks at the bottom of the notebook.****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c0e47f2d84be518d4e2f345c77914877",
          "grade": false,
          "grade_id": "cell-5cf9478351835437",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d4ZE1m9noMQ5"
      },
      "source": [
        "# Product Review Classification\n",
        "\n",
        "## Business Understanding\n",
        "Our company wants a tool that will automatically classify product reviews as _positive_ or _negative_ reviews, based on the features of the review.  This will help our Product team to perform more sophisticated analyses in the future to help ensure customer satisfaction.\n",
        "\n",
        "## Data Understanding\n",
        "We have a labeled collection of 20,000 product reviews, with an equal split of positive and negative reviews. The dataset contains the following features:\n",
        "\n",
        " - `ProductId` Unique identifier for the product\n",
        " - `UserId` Unqiue identifier for the user\n",
        " - `ProfileName` Profile name of the user\n",
        " - `HelpfulnessNumerator` Number of users who found the review helpful\n",
        " - `HelpfulnessDenominator` Number of users who indicated whether they found the review helpful or not\n",
        " - `Time` Timestamp for the review\n",
        " - `Summary` Brief summary of the review\n",
        " - `Text` Text of the review\n",
        " - `PositiveReview` 1 if this was labeled as a positive review, 0 if it was labeled as a negative review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEPaLqIjoMQ5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d12ad4b9bbc742a1963e558849c5da90",
          "grade": false,
          "grade_id": "cell-8f19c966797e8ca7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "521q-AX5oMQ8",
        "outputId": "6a054e51-0f6e-4a78-9841-742bf4be5bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head(3)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>PositiveReview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B002QWHJOU</td>\n",
              "      <td>A37565LZHTG1VH</td>\n",
              "      <td>C. Maltese</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1305331200</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>This is a great product. My 2 year old Golden ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B000ESLJ6C</td>\n",
              "      <td>AMUAWXDJHE4D2</td>\n",
              "      <td>angieseashore</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1320710400</td>\n",
              "      <td>Was there a recipe change?</td>\n",
              "      <td>I have been drinking Pero ever since I was a l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B004IJJQK4</td>\n",
              "      <td>AMHHNAFJ9L958</td>\n",
              "      <td>A M</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1321747200</td>\n",
              "      <td>These taste so bland.</td>\n",
              "      <td>Look, each pack contains two servings of 120 c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ProductId  ... PositiveReview\n",
              "0  B002QWHJOU  ...              1\n",
              "1  B000ESLJ6C  ...              0\n",
              "2  B004IJJQK4  ...              0\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "00b5b97f4dc78599523bf55af4044601",
          "grade": false,
          "grade_id": "cell-de50c050862f1ec0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7ppE_ufNoMQ_"
      },
      "source": [
        "The data has already been cleaned, so there are no missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4f69c7ac9899512c8d7ca3b061ede167",
          "grade": false,
          "grade_id": "cell-d5c61a2ee001ee18",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "knaC1MV5oMQ_",
        "outputId": "8845cb1f-4182-4023-c063-211c898d261f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProductId                 0\n",
              "UserId                    0\n",
              "ProfileName               0\n",
              "HelpfulnessNumerator      0\n",
              "HelpfulnessDenominator    0\n",
              "Time                      0\n",
              "Summary                   0\n",
              "Text                      0\n",
              "PositiveReview            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a5cdc79e44ba7459c1e132c0a7098474",
          "grade": false,
          "grade_id": "cell-bc36cabb3eca9892",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "KN1wZuPCoMRC"
      },
      "source": [
        "`PositiveReview` is the target, and all other columns are features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "437bbabc250883a93140c08c34faf2af",
          "grade": false,
          "grade_id": "cell-d0be448b581f518c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1x417949oMRD"
      },
      "source": [
        "X = df.drop(\"PositiveReview\", axis=1)\n",
        "y = df[\"PositiveReview\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1115754d427a712daec8732dfeee212e",
          "grade": false,
          "grade_id": "cell-df5c1e71d5e49339",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JxrbKnGCoMRG"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "First, split into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a90fca953115932250bd3fdbbe3fd8c3",
          "grade": false,
          "grade_id": "cell-d86566df8ed2de47",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WXho2SLxoMRG",
        "outputId": "caf22825-3f4d-4414-a44f-944c03238af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "09723cad404018217d8cfde509450f31",
          "grade": false,
          "grade_id": "cell-42807fda590da223",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4O6GAfAGoMRJ"
      },
      "source": [
        "Second, prepare for modeling. The following `Pipeline` prepares all data for modeling.  It one-hot encodes the `ProductId`, applies a tf-idf vectorizer to the `Summary` and `Text`, keeps the numeric columns as-is, and drops all other columns.\n",
        "\n",
        "The following code may take up to 1 minute to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1f988fd3838dc0c71c160772945f5037",
          "grade": false,
          "grade_id": "cell-3a518026cdbd1cbd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "aKXWCdxSoMRJ",
        "outputId": "3fa8a55c-32de-4197-abbe-8a1bdfc72099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def drop_irrelevant_columns(X):\n",
        "    return X.drop([\"UserId\", \"ProfileName\"], axis=1)\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"drop_columns\", FunctionTransformer(drop_irrelevant_columns,\n",
        "                                        validate=False)),\n",
        "    (\"transform_text_columns\", ColumnTransformer(transformers=[\n",
        "        (\"ohe\", OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\", sparse=False), [\"ProductId\"]),\n",
        "        (\"summary-tf-idf\", TfidfVectorizer(max_features=1000), \"Summary\"),\n",
        "        (\"text-tf-idf\", TfidfVectorizer(max_features=1000), \"Text\")\n",
        "    ], remainder=\"passthrough\"))\n",
        "])\n",
        "\n",
        "X_train_transformed = pipeline.fit_transform(X_train)\n",
        "X_test_transformed = pipeline.transform(X_test)\n",
        "\n",
        "X_train_transformed.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 11275)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG4pqFJdoMRM",
        "outputId": "3937c68c-e45a-4852-fd94-dcb59fd81599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "pd.DataFrame(X_train_transformed).describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>11235</th>\n",
              "      <th>11236</th>\n",
              "      <th>11237</th>\n",
              "      <th>11238</th>\n",
              "      <th>11239</th>\n",
              "      <th>11240</th>\n",
              "      <th>11241</th>\n",
              "      <th>11242</th>\n",
              "      <th>11243</th>\n",
              "      <th>11244</th>\n",
              "      <th>11245</th>\n",
              "      <th>11246</th>\n",
              "      <th>11247</th>\n",
              "      <th>11248</th>\n",
              "      <th>11249</th>\n",
              "      <th>11250</th>\n",
              "      <th>11251</th>\n",
              "      <th>11252</th>\n",
              "      <th>11253</th>\n",
              "      <th>11254</th>\n",
              "      <th>11255</th>\n",
              "      <th>11256</th>\n",
              "      <th>11257</th>\n",
              "      <th>11258</th>\n",
              "      <th>11259</th>\n",
              "      <th>11260</th>\n",
              "      <th>11261</th>\n",
              "      <th>11262</th>\n",
              "      <th>11263</th>\n",
              "      <th>11264</th>\n",
              "      <th>11265</th>\n",
              "      <th>11266</th>\n",
              "      <th>11267</th>\n",
              "      <th>11268</th>\n",
              "      <th>11269</th>\n",
              "      <th>11270</th>\n",
              "      <th>11271</th>\n",
              "      <th>11272</th>\n",
              "      <th>11273</th>\n",
              "      <th>11274</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "      <td>1.500000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011004</td>\n",
              "      <td>0.005522</td>\n",
              "      <td>0.003421</td>\n",
              "      <td>0.008198</td>\n",
              "      <td>0.006175</td>\n",
              "      <td>0.005403</td>\n",
              "      <td>0.002440</td>\n",
              "      <td>0.019506</td>\n",
              "      <td>0.004134</td>\n",
              "      <td>0.032874</td>\n",
              "      <td>0.002112</td>\n",
              "      <td>0.006229</td>\n",
              "      <td>0.004862</td>\n",
              "      <td>0.005405</td>\n",
              "      <td>0.005429</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.002757</td>\n",
              "      <td>0.001875</td>\n",
              "      <td>0.002223</td>\n",
              "      <td>0.003910</td>\n",
              "      <td>0.005442</td>\n",
              "      <td>0.018968</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>0.001757</td>\n",
              "      <td>0.003608</td>\n",
              "      <td>0.002715</td>\n",
              "      <td>0.004909</td>\n",
              "      <td>0.007083</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.002013</td>\n",
              "      <td>0.003330</td>\n",
              "      <td>0.037335</td>\n",
              "      <td>0.014392</td>\n",
              "      <td>0.001970</td>\n",
              "      <td>0.001686</td>\n",
              "      <td>0.002440</td>\n",
              "      <td>0.001540</td>\n",
              "      <td>2.164467</td>\n",
              "      <td>3.281067</td>\n",
              "      <td>1.299116e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.014141</td>\n",
              "      <td>0.016328</td>\n",
              "      <td>0.016328</td>\n",
              "      <td>0.018255</td>\n",
              "      <td>0.018255</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.011547</td>\n",
              "      <td>0.024488</td>\n",
              "      <td>0.018255</td>\n",
              "      <td>0.018255</td>\n",
              "      <td>0.011547</td>\n",
              "      <td>0.011547</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.011547</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.021598</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.018255</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.014141</td>\n",
              "      <td>0.018255</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.011547</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.018255</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.014141</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035838</td>\n",
              "      <td>0.027876</td>\n",
              "      <td>0.029630</td>\n",
              "      <td>0.034006</td>\n",
              "      <td>0.031810</td>\n",
              "      <td>0.029713</td>\n",
              "      <td>0.023626</td>\n",
              "      <td>0.046646</td>\n",
              "      <td>0.028120</td>\n",
              "      <td>0.050122</td>\n",
              "      <td>0.020066</td>\n",
              "      <td>0.030872</td>\n",
              "      <td>0.028998</td>\n",
              "      <td>0.032845</td>\n",
              "      <td>0.031321</td>\n",
              "      <td>0.017807</td>\n",
              "      <td>0.024452</td>\n",
              "      <td>0.019869</td>\n",
              "      <td>0.020717</td>\n",
              "      <td>0.028609</td>\n",
              "      <td>0.031331</td>\n",
              "      <td>0.046333</td>\n",
              "      <td>0.024009</td>\n",
              "      <td>0.020522</td>\n",
              "      <td>0.025710</td>\n",
              "      <td>0.021529</td>\n",
              "      <td>0.029053</td>\n",
              "      <td>0.031997</td>\n",
              "      <td>0.016785</td>\n",
              "      <td>0.018368</td>\n",
              "      <td>0.025642</td>\n",
              "      <td>0.068356</td>\n",
              "      <td>0.044589</td>\n",
              "      <td>0.019136</td>\n",
              "      <td>0.023057</td>\n",
              "      <td>0.025178</td>\n",
              "      <td>0.019416</td>\n",
              "      <td>6.776367</td>\n",
              "      <td>8.285617</td>\n",
              "      <td>4.603391e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.046045e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.277942e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.313626e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064079</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.061488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.333411e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.392434</td>\n",
              "      <td>0.340942</td>\n",
              "      <td>0.687126</td>\n",
              "      <td>0.472046</td>\n",
              "      <td>0.408876</td>\n",
              "      <td>0.407992</td>\n",
              "      <td>0.409031</td>\n",
              "      <td>0.449051</td>\n",
              "      <td>0.386988</td>\n",
              "      <td>0.380110</td>\n",
              "      <td>0.431835</td>\n",
              "      <td>0.428901</td>\n",
              "      <td>0.424399</td>\n",
              "      <td>0.504743</td>\n",
              "      <td>0.537120</td>\n",
              "      <td>0.423541</td>\n",
              "      <td>0.611497</td>\n",
              "      <td>0.430708</td>\n",
              "      <td>0.415425</td>\n",
              "      <td>0.513928</td>\n",
              "      <td>0.463294</td>\n",
              "      <td>0.456507</td>\n",
              "      <td>0.422613</td>\n",
              "      <td>0.746669</td>\n",
              "      <td>0.462461</td>\n",
              "      <td>0.317445</td>\n",
              "      <td>0.503622</td>\n",
              "      <td>0.386642</td>\n",
              "      <td>0.470237</td>\n",
              "      <td>0.426204</td>\n",
              "      <td>0.638224</td>\n",
              "      <td>0.495204</td>\n",
              "      <td>0.428959</td>\n",
              "      <td>0.424191</td>\n",
              "      <td>0.870707</td>\n",
              "      <td>0.671060</td>\n",
              "      <td>0.614981</td>\n",
              "      <td>436.000000</td>\n",
              "      <td>486.000000</td>\n",
              "      <td>1.351210e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  11275 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0             1      ...         11273         11274\n",
              "count  15000.000000  15000.000000  ...  15000.000000  1.500000e+04\n",
              "mean       0.000067      0.000200  ...      3.281067  1.299116e+09\n",
              "std        0.008165      0.014141  ...      8.285617  4.603391e+07\n",
              "min        0.000000      0.000000  ...      0.000000  1.046045e+09\n",
              "25%        0.000000      0.000000  ...      0.000000  1.277942e+09\n",
              "50%        0.000000      0.000000  ...      1.000000  1.313626e+09\n",
              "75%        0.000000      0.000000  ...      4.000000  1.333411e+09\n",
              "max        1.000000      1.000000  ...    486.000000  1.351210e+09\n",
              "\n",
              "[8 rows x 11275 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6490b9c101d9afea986acda457da5107",
          "grade": false,
          "grade_id": "cell-e29707b947032a36",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_R_8IxuYoMRP"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "Fit a `RandomForestClassifier` with the best hyperparameters.  The following code may take up to 1 minute to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "732efe37a7710f3cc076a248d5a1f7b3",
          "grade": false,
          "grade_id": "cell-d71f1997913733d0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "VmtET6cqoMRQ",
        "outputId": "52212362-5eab-4d95-ec35-e90f41e059bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rfc = RandomForestClassifier(\n",
        "    random_state=42,\n",
        "    n_estimators=100,\n",
        "    max_depth=30,\n",
        "    min_samples_split=15,\n",
        "    min_samples_leaf=1\n",
        ")\n",
        "rfc.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=30, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=15,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c01a42b85a3919e299a758aae2b85587",
          "grade": false,
          "grade_id": "cell-7b20cf324ce452ab",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "TXM-2Gp4oMRT"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "We are using _accuracy_ as our metric, which is the default metric in Scikit-Learn, so it is possible to just use the built-in `.score` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f563d53773e7219c677794bed839139a",
          "grade": false,
          "grade_id": "cell-10cb2bb51ffa9bc2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "alTDbQ7_oMRT",
        "outputId": "2b700ab3-81a0-426c-8657-72f1c5532030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Train accuracy:\", rfc.score(X_train_transformed, y_train))\n",
        "print(\"Test accuracy:\", rfc.score(X_test_transformed, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.9826666666666667\n",
            "Test accuracy: 0.913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "18959f145f83655fad150c531b926894",
          "grade": false,
          "grade_id": "cell-e928f8fa4da3ea0a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "aO6XZGK_oMRW",
        "outputId": "63e2dcba-303c-43ff-cb8d-158fd96b0139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Train confusion matrix:\")\n",
        "print(confusion_matrix(y_train, rfc.predict(X_train_transformed)))\n",
        "print(\"Test confusion matrix:\")\n",
        "print(confusion_matrix(y_test, rfc.predict(X_test_transformed)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train confusion matrix:\n",
            "[[7312  177]\n",
            " [  83 7428]]\n",
            "Test confusion matrix:\n",
            "[[2293  218]\n",
            " [ 217 2272]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "12c85f6c3cb2793e2a0a1cac84995789",
          "grade": false,
          "grade_id": "cell-798fce8a6c47cc98",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "n86b7e02oMRY"
      },
      "source": [
        "## Business Interpretation\n",
        "\n",
        "The tuned Random Forest Classifier model appears to be somewhat overfit on the training data, but nevertheless achieves 91% accuracy on the test data.  Of the 9% of mislabeled comments, about half are false positives and half are false negatives.\n",
        "\n",
        "Because this is a balanced dataset, 91% accuracy is a substantial improvement over a 50% baseline.  This model is ready for production use for decision support."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "74df00ffd61c5bbc137e6c8e60072fdf",
          "grade": false,
          "grade_id": "cell-21ac6d0dc288ef62",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cprmIQwHoMRY"
      },
      "source": [
        "## Please add you work below.\n",
        "> Rubric items have been provided as guidance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "41d131fd6dd98e01edfd6213fb236b81",
          "grade": false,
          "grade_id": "cell-d94af57df5d3f8a5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "XePAKTgSoMRZ"
      },
      "source": [
        "### 1) Data Preparation\n",
        "\n",
        "A train-test split has already been performed.\n",
        "\n",
        "Additionally, there is already a pipeline in place that drops some columns and converts all text columns into a numeric format for modeling.\n",
        "\n",
        "**Your only additional data preparation task is feature scaling.**  Tree-based models like Random Forest Classifiers do not require scaling, but TensorFlow neural networks do.\n",
        "\n",
        "There are two main strategies you can take for this task:\n",
        "\n",
        "#### Scaling within the existing pipeline\n",
        "\n",
        "If you are comfortable with pipelines, this is the more polished/professional route.\n",
        "\n",
        "1. Make a new pipeline, with a `StandardScaler` as the final step.  You can nest the steps of the previous pipeline inside of this new pipeline\n",
        "2. Generate a new `X_train_transformed_scaled` by calling `.fit_transform` on the new pipeline\n",
        "3. Generate a new `X_test_transformed_scaled` by calling `.transform` on the new pipeline\n",
        "\n",
        "#### Scaling after the pipeline has finished\n",
        "\n",
        "This is a better strategy if you are not as comfortable with pipelines.\n",
        "\n",
        "1. Instantiate a `StandardScaler` object\n",
        "2. Generate a new `X_train_transformed_scaled` by calling `.fit_transform` on the scaler object, after you have called `.fit_transform` on the pipeline\n",
        "3. Generate a new `X_test_transformed_scaled` by calling `.transform` on the scaler object, after you have called `.transform` on the pipeline\n",
        "\n",
        "If you are getting stuck at this step, skip it.  The model will still be able to fit, although the performance will be worse.  Keep in mind whether or not you scaled the data in your final analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz8PDM7V4CvH"
      },
      "source": [
        "# Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg2Bx4AVoMRZ",
        "outputId": "9128e501-8f4c-4d63-b931-0dcd4daa8f21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# create a new pipeline with StandardScaler at the end.  Since all features will be numeric after\n",
        "# the first transformations, and scaling doesn't hurt one-hot-encoding, we will scale all features.\n",
        "\n",
        "newpipe = Pipeline(steps=[\n",
        "    (\"drop_columns\", FunctionTransformer(drop_irrelevant_columns,\n",
        "                                        validate=False)),\n",
        "    (\"transform_text_columns\", ColumnTransformer(transformers=[\n",
        "        (\"ohe\", OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\", sparse=False), [\"ProductId\"]),\n",
        "        (\"summary-tf-idf\", TfidfVectorizer(max_features=1000), \"Summary\"),\n",
        "        (\"text-tf-idf\", TfidfVectorizer(max_features=1000), \"Text\"),\n",
        "    ], remainder=\"passthrough\")),\n",
        "    ('standard-scaler',StandardScaler())])\n",
        "\n",
        "\n",
        "X_train_transformed_ss = newpipe.fit_transform(X_train)\n",
        "X_test_transformed_ss = newpipe.transform(X_test)\n",
        "\n",
        "X_train_transformed_ss.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 11275)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8c2537bad916f3ff44de14f71d174023",
          "grade": false,
          "grade_id": "cell-fd9103cc41e6498e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "_tLnfH6toMRc"
      },
      "source": [
        "### 2) Modeling\n",
        "\n",
        "Build a neural network classifier.  Specifically, use the `keras` submodule of the `tensorflow` library to build a multi-layer perceptron model with the `Sequential` interface.\n",
        "\n",
        "See the [`tf.keras` documentation](https://www.tensorflow.org/guide/keras/overview) for an overview on the use of `Sequential` models. See the [Keras layers documentation](https://keras.io/layers/core/) for descriptions of the `Dense` layer options.  \n",
        "\n",
        "1. Instantiate a `Sequential` model\n",
        "2. Add an input `Dense` layer.  You'll need to specify a `input_shape` = (11275,) because this is the number of features of the transformed dataset.\n",
        "3. Add 2 `Dense` hidden layers.  They can have any number of units, but keep in mind that more units will require more processing power.  We recommend an initial `units` of 64 for processing power reasons.\n",
        "4. Add a final `Dense` output layer.  This layer must have exactly 1 unit because we are doing a binary prediction task.\n",
        "5. Compile the `Sequential` model\n",
        "6. Fit the `Sequential` model on the preprocessed training data (`X_train_transformed_scaled`) with a b`batch_size` of 50 and `epochs` of 5 for processing power reasons.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOLAr-TLoMRd"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f9Cgm04oMRh"
      },
      "source": [
        "def make_model1():\n",
        "    import tensorflow as tf\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "\n",
        "    #instantiate a new, basic sequential model with dense layers\n",
        "    model = Sequential()\n",
        "\n",
        "    #model has 11275 features, so that will be the input shape.  We will use ReLU activations\n",
        "    #and add 2 more dense hidden layers\n",
        "    model.add(Dense(64, input_shape = (11275,), activation = 'relu'))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "\n",
        "    #since we have a binary target, 1 output node and a sigmoid activation is appropriate\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCg5UvT8oMRk",
        "outputId": "2c0c4629-9942-4347-c48e-89998e8a7f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from IPython.display import display \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "model = KerasClassifier(build_fn = make_model1, epochs = 5, batch_size = 50, verbose = 0)\n",
        "\n",
        "pipe = Pipeline([('model', model)])\n",
        "\n",
        "results = cross_val_score(pipe, X_train_transformed_ss, y_train, cv = kfold, scoring = 'accuracy')\n",
        "print('CV Results:')\n",
        "display(pd.DataFrame(results))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "CV Results:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0\n",
              "0  0.9156\n",
              "1  0.9080\n",
              "2  0.9134"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ca26d54681429b00d7f86b4e536ac22d",
          "grade": false,
          "grade_id": "cell-414eb9a5881a0913",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "N6sIsRSyoMRn"
      },
      "source": [
        "### 3) Model Tuning + Feature Engineering\n",
        "\n",
        "If you are running out of time, skip this step.\n",
        "\n",
        "Tune the neural network model to improve performance.  This could include steps such as increasing the units, changing the activation functions, or adding regularization.\n",
        "\n",
        "We recommend using using a `validation_split` of 0.1 to understand model performance without utilizing the test holdout set.\n",
        "\n",
        "You can also return to the preprocessing phase, and add additional features to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZsp1DQioMRn"
      },
      "source": [
        "def make_model2():\n",
        "    import tensorflow as tf\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "\n",
        "    #instantiate a new, basic sequential model with dense layers\n",
        "    model = Sequential()\n",
        "\n",
        "    #model has 11275 features, so that will be the input shape.  We will use ReLU activations\n",
        "    #and add 3 more dense hidden layers, and add dropout layers for regularization\n",
        "    model.add(Dense(64, input_shape = (11275,), activation = 'relu'))\n",
        "    model.add(Dropout(rate = .2))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .2))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .2))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .2))\n",
        "\n",
        "    #since we have a binary target, 1 output node and a sigmoid activation is appropriate\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5lGyDQ9oMRp",
        "outputId": "e4508aad-9bfd-4912-eef7-778ac76595be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "model = KerasClassifier(build_fn = make_model2, epochs = 5, batch_size = 50, verbose = 0)\n",
        "\n",
        "pipe = Pipeline([('model', model)])\n",
        "\n",
        "results = cross_val_score(pipe, X_train_transformed_ss, y_train, cv = kfold, scoring = 'accuracy')\n",
        "print('CV Results:')\n",
        "display(pd.DataFrame(results))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV Results:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0\n",
              "0  0.9204\n",
              "1  0.9160\n",
              "2  0.9158"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O8VpmR7oMRs"
      },
      "source": [
        "def make_model3():\n",
        "    import tensorflow as tf\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "\n",
        "    #instantiate a new, basic sequential model with dense layers\n",
        "    model = Sequential()\n",
        "\n",
        "    #model has 11275 features, so that will be the input shape.  We will use ReLU activations\n",
        "    #and add 4 more dense hidden layers, increase the neurons per layer, and increase the\n",
        "    #regularization (which seems to be helping the cross validation scores)\n",
        "    model.add(Dense(64, input_shape = (11275,), activation = 'relu'))\n",
        "    model.add(Dropout(rate = .4))\n",
        "    model.add(Dense(128, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .5))\n",
        "    model.add(Dense(128, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .5))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .3))\n",
        "    model.add(Dense(32, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .2))\n",
        "\n",
        "    #since we have a binary target, 1 output node and a sigmoid activation is appropriate\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS7TWwivoMRw",
        "outputId": "28d96fb2-b253-4e38-9cc2-88257fd38bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "model = KerasClassifier(build_fn = make_model3, epochs = 5, batch_size = 50, verbose = 0)\n",
        "\n",
        "pipe = Pipeline([('model', model)])\n",
        "\n",
        "results = cross_val_score(pipe, X_train_transformed_ss, y_train, cv = kfold, scoring = 'accuracy')\n",
        "print('CV Results:')\n",
        "display(pd.DataFrame(results))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV Results:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0\n",
              "0  0.9304\n",
              "1  0.9258\n",
              "2  0.9192"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNXFxNuCoMRy"
      },
      "source": [
        "def make_model4():\n",
        "    import tensorflow as tf\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "\n",
        "    #instantiate a new, basic sequential model with dense layers\n",
        "    model = Sequential()\n",
        "\n",
        "    #model has 11275 features, so that will be the input shape.  We will use ReLU activations\n",
        "    #and add 2 more dense hidden layers, increase neurons again, and keep strong regularization\n",
        "    model.add(Dense(256, input_shape = (11275,), activation = 'relu'))\n",
        "    model.add(Dropout(rate = .7))\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .5))\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .5))\n",
        "\n",
        "\n",
        "    #since we have a binary target, 1 output node and a sigmoid activation is appropriate\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5DBO0cqoMR0",
        "outputId": "83677adf-416a-4009-9a46-c3a36e68e607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "model = KerasClassifier(build_fn = make_model4, epochs = 5, batch_size = 50, verbose = 0)\n",
        "\n",
        "pipe = Pipeline([('model', model)])\n",
        "\n",
        "results = cross_val_score(pipe, X_train_transformed_ss, y_train, cv = kfold, scoring = 'accuracy')\n",
        "print('CV Results:')\n",
        "display(pd.DataFrame(results))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV Results:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0\n",
              "0  0.9316\n",
              "1  0.9264\n",
              "2  0.9250"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKho5DEwq3II"
      },
      "source": [
        "def make_model5():\n",
        "    import tensorflow as tf\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.layers import Dropout\n",
        "\n",
        "    #instantiate a new, basic sequential model with dense layers\n",
        "    model = Sequential()\n",
        "\n",
        "    #model has 11275 features, so that will be the input shape.  We will use ReLU activations\n",
        "    #and add 3 more dense hidden layers, increase neurons again, and keep strong regularization\n",
        "    model.add(Dense(256, input_shape = (11275,), activation = 'relu'))\n",
        "    model.add(Dropout(rate = .8))\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .5))\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .5))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dropout(rate = .3))\n",
        "\n",
        "    #since we have a binary target, 1 output node and a sigmoid activation is appropriate\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMCQ4g31q3IM",
        "outputId": "83b537f3-279a-483b-a12a-55ae958b41c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "model = KerasClassifier(build_fn = make_model5, epochs = 5, batch_size = 50, verbose = 0)\n",
        "\n",
        "pipe = Pipeline([('model', model)])\n",
        "\n",
        "results = cross_val_score(pipe, X_train_transformed_ss, y_train, cv = kfold, scoring = 'accuracy')\n",
        "print('CV Results:')\n",
        "display(pd.DataFrame(results))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV Results:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9218</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0\n",
              "0  0.9250\n",
              "1  0.9310\n",
              "2  0.9218"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7790b06b01dfc645959055809c9d2614",
          "grade": false,
          "grade_id": "cell-22bc9c383d5836b5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "IBdngBzMoMR2"
      },
      "source": [
        "### 4) Model Evaluation\n",
        "\n",
        "Choose a final `Sequential` model, add layers, and compile.  Fit the model on the preprocessed training data (`X_train_transformed_scaled`, `y_train`) and evaluate on the preprocessed testing data (`X_test_transformed_scaled`, `y_test`) using `accuracy_score`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM1qr_nUoMR3",
        "outputId": "9d2b8b2d-6566-4ec2-f2c1-101a73bc08e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pipe.fit(X_train_transformed_ss,y_train)\n",
        "ypred = pipe.predict(X_test_transformed_ss)\n",
        "print('Confusion Matrix')\n",
        "display(pd.DataFrame(confusion_matrix(y_test,ypred)))\n",
        "print('accuracy score is:')\n",
        "accuracy_score(y_test,ypred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2338</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>138</td>\n",
              "      <td>2351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1\n",
              "0  2338   173\n",
              "1   138  2351"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy score is:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1652e990b0d6d78b7c8f5fa24fe058ad",
          "grade": false,
          "grade_id": "cell-09fa9ba130b03198",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "isPQ-pZooMR5"
      },
      "source": [
        "### 5) Technical Communication\n",
        "\n",
        "Write a paragraph explaining whether Northwind Trading Company should switch to using your new neural network model, or continue to use the Random Forest Classifier.  Beyond a simple comparison of performance, try to take into consideration additional considerations such as:\n",
        "\n",
        " - Computational complexity/resource use\n",
        " - Anticipated performance on future datasets (how might the data change over time?)\n",
        " - Types of mistakes made by the two kinds of models\n",
        "\n",
        "You can make guesses or inferences about these considerations.\n",
        "\n",
        "**Include at least one visualization** comparing the two types of models.  Possible points of comparison could include ROC curves, colorized confusion matrices, or time needed to train.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkl5r_D009Ho"
      },
      "source": [
        "## Stats for Random Forest Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMRyLQ4Gy-VX",
        "outputId": "d0367234-16b2-4e0d-fa17-531799e16c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Training and Evaluation\n",
        "start = time.time()\n",
        "rfc.fit(X_train_transformed, y_train)\n",
        "rfcconfusion_matrix = confusion_matrix(y_test, rfc.predict(X_test_transformed),\n",
        "                                       normalize = 'true')\n",
        "ypred = rfc.predict(X_test_transformed)\n",
        "end = time.time()\n",
        "rfc_time = end - start\n",
        "\n",
        "#Reporting\n",
        "print(\"RFC Test accuracy:\", accuracy_score(y_test, ypred))\n",
        "\n",
        "print(\"RFC Test confusion matrix:\")\n",
        "sns.heatmap(rfcconfusion_matrix, annot = True, xticklabels = ['Negative','Positive'],\n",
        "            yticklabels = ['Negatvie','Positive'])\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "plt.show()\n",
        "\n",
        "print(f'time to retrain, predict, and test for random forest classificer is {rfc_time} seconds')\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RFC Test accuracy: 0.913\n",
            "RFC Test confusion matrix:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time to retrain, predict, and test for random forest classificer is 28.2722806930542 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CF0DkFt32CQ"
      },
      "source": [
        "## Stats for Deep Learning Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhOAlixdvrxQ",
        "outputId": "34c208f8-6267-4297-b8e2-d61885e0ff06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "#Training and evaluation\n",
        "\n",
        "NNmodel = KerasClassifier(build_fn = make_model4, epochs = 5, batch_size = 50, verbose = 0)\n",
        "pipe = Pipeline([('model', NNmodel)])\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "pipe.fit(X_train_transformed_ss,y_train)\n",
        "ypred = pipe.predict(X_test_transformed_ss)\n",
        "NN_confusion_matrix = confusion_matrix(y_test,ypred, normalize = 'true')\n",
        "accuracy_score(y_test,ypred)\n",
        "\n",
        "end = time.time()\n",
        "NNtime = end - start\n",
        "\n",
        "#Reporting\n",
        "print('test accuracy score is:', accuracy_score(y_test,ypred))\n",
        "\n",
        "print('confusion matrix for neural network is:')\n",
        "sns.heatmap(NN_confusion_matrix, annot = True, xticklabels = ['Negative','Positive'],\n",
        "            yticklabels = ['Negatvie','Positive'])\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "plt.show()\n",
        "\n",
        "print(f'time to retrain, predict, and test for neural netword is {NNtime} seconds')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Confusion Matrix\n",
            "test accuracy score is: 0.9396\n",
            "confusion matrix for neural network is:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time to retrain, predict, and test for neural netword is 5.0213682651519775 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHxpnwDN1ttH"
      },
      "source": [
        "# Results:\n",
        "### Increase training and predicting speed\n",
        "When run on a server with access to a GPU, you can see that the neural network we have designed run much faster, in fact 6x faster.  This is because Tensorflow can take advantage of distributed processing to use multiple available processors to complete a task, while the SKlearn random forest library only makes use of one.\n",
        "\n",
        "### Improved Accuracy\n",
        "Our deep learning model is 3% more accurate than the random forest classifier, making both fewer false negative and fewer false positive errors.  Only 6% of negative reviews are misclassified as positive and only 7% of positive reviews are misclassified as negative.  In comparision, the random forest classifier misclassifies almost 9% of each.\n",
        "\n",
        "### Summary:\n",
        "Our engineered and tuned deep learning neural network model is an improvement on the random forest classifier in training speed, prediction speed, and accuracy across both classes.  It is a superior model.\n",
        "\n",
        "### Note\n",
        "The deep learning model is optimal when run on distributed computing architectures.  This includes computers with strong GPUs, but also many cloud available servies such as AWS and Google cloud services.  This model was developed, trained, and benchmarked on Google Colab."
      ]
    }
  ]
}